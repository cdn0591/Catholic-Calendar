import cloudscraper
from bs4 import BeautifulSoup
from icalendar import Calendar, Event
from datetime import datetime, timezone, timedelta
import re
import hashlib
import time
import random
import sys

try:
    import zhconv
except ImportError:
    zhconv = None

# ===========================
# 1. ç½‘ç»œè¯·æ±‚æ¨¡å—
# ===========================
def fetch_calendar_data(url):
    scraper = cloudscraper.create_scraper(
        browser={'browser': 'chrome', 'platform': 'windows', 'desktop': True}
    )
    
    max_retries = 5
    for attempt in range(max_retries):
        try:
            print(f"ğŸ”„ [å°è¯• {attempt + 1}/{max_retries}] è¿æ¥: {url} ...")
            response = scraper.get(url, timeout=60)
            response.encoding = 'utf-8'
            
            if response.status_code == 200 and len(response.text) > 2000:
                return response.text
            
            print(f"   âš ï¸ çŠ¶æ€ç  {response.status_code} æˆ–å†…å®¹è¿‡çŸ­ï¼Œé‡è¯•...")
            time.sleep(random.randint(5, 10))
                
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            time.sleep(5)
            
    return None

# ===========================
# 2. é¢œè‰²è¯†åˆ«é€»è¾‘ (å‡çº§ç‰ˆï¼šæ”¯æŒå¤šè‰² + æ™ºèƒ½æ¨æ–­)
# ===========================
def get_liturgical_emoji(cell_soup, row_soup, text_content):
    text_content = text_content.strip()
    
    # 0. ç‰¹æ®ŠèŠ‚æ—¥å¼ºåˆ¶ç¡¬ç¼–ç  (æœ€é«˜ä¼˜å…ˆçº§)
    if "è¿½æ€å·²äº¡" in text_content: return "ğŸŸ£âš«âšª "
    
    # å®šä¹‰é¢œè‰²è§„åˆ™åˆ—è¡¨
    # æ ¼å¼: (Emoji, [HTMLç‰¹å¾è¯... , ä¸­æ–‡æ–‡æœ¬å…³é”®è¯...])
    PATTERNS = [
        ("ğŸ”´ ", ["red", "day_r", "#ff0000", "#f00", "æ®‰é“", "åœ£æ", "è–æ", "åœ£ç¥", "è–ç¥", "å—éš¾", "å—é›£"]),
        ("ğŸŸ£ ", ["violet", "purple", "day_v", "day_p", "#800080", "å››æ—¬æœŸ", "å°†ä¸´æœŸ", "å°‡è‡¨æœŸ", "å¿æ‚”", "æ‡ºæ‚”"]),
        ("ğŸŸ¢ ", ["green", "day_g", "#008000", "#00ff00", "å¸¸å¹´æœŸ"]),
        ("âš« ", ["black", "day_b", "#000000", "#000"]),
        ("âšª ", ["white", "day_w", "#ffffff", "#fff", "åœ£è¯", "è–èª•", "å¤æ´»", "å¾©æ´»", "åœ£æ¯", "è–æ¯", "ç™½", "è¯¸åœ£", "è«¸è–", "çŒ®ä¸»", "ç»ä¸»", "è€¶ç¨£å‡å¤©"]),
        ("ğŸŸ¡ ", ["gold", "yellow", "day_y", "#ffd700"]),
    ]
    
    # å¼±è§„åˆ™ï¼šä»…å½“æœªæ£€æµ‹åˆ°ä»»ä½•é¢œè‰²æ—¶ï¼Œé€šè¿‡è¿™äº›è¯æ¨æ–­ä¸ºç™½è‰²
    WEAK_WHITE_KEYWORDS = ["çºª", "ç´€", "åº†", "æ…¶", "åœ£", "è–"]

    # 1. æ”¶é›† HTML å±æ€§
    check_pool = []
    for tag in [cell_soup] + list(cell_soup.find_all(True)):
        cls = " ".join(tag.get('class', [])).lower()
        sty = str(tag.get('style', '')).lower()
        check_pool.append(f"{cls} {sty}")

    if row_soup:
        r_cls = " ".join(row_soup.get('class', [])).lower()
        r_sty = str(row_soup.get('style', '')).lower()
        check_pool.append(f"{r_cls} {r_sty}")

    full_html_str = " | ".join(check_pool)

    # 2. åŒ¹é…å¼ºè§„åˆ™ (HTML + æ–‡æœ¬)
    found_emojis = []

    # ç­–ç•¥ A: HTML å±æ€§åŒ¹é…
    for emoji, keywords in PATTERNS:
        for kw in keywords:
            if not re.search(r'[\u4e00-\u9fff]', kw): # åªæŸ¥è‹±æ–‡ä»£ç 
                if kw in full_html_str:
                    if emoji not in found_emojis: found_emojis.append(emoji)
                    break 

    # ç­–ç•¥ B: æ–‡æœ¬å†…å®¹åŒ¹é… (è¡¥å……HTMLæ²¡å†™çš„æƒ…å†µ)
    # åªæœ‰å½“è¯¥é¢œè‰²è¿˜æ²¡è¢« HTML åŒ¹é…åˆ°æ—¶æ‰æŸ¥æ–‡æœ¬
    for emoji, keywords in PATTERNS:
        if emoji in found_emojis: continue 
        for kw in keywords:
            if re.search(r'[\u4e00-\u9fff]', kw): # åªæŸ¥ä¸­æ–‡å…³é”®è¯
                if kw in text_content:
                    found_emojis.append(emoji)
                    break

    # 3. è¡¥æ¼é€»è¾‘ (å¼±è§„åˆ™)
    # å¦‚æœæ­¤æ—¶æ²¡æœ‰ä»»ä½•é¢œè‰²ï¼Œä¸”æ–‡æœ¬åŒ…å«â€œåœ£/çºª/åº†â€ï¼Œåˆ™é»˜è®¤ä¸ºç™½è‰²
    if not found_emojis:
        for kw in WEAK_WHITE_KEYWORDS:
            if kw in text_content:
                return "âšª " # ç›´æ¥è¿”å›ï¼Œä¸å†æ‹¼æ¥
    
    return "".join(found_emojis)

# ===========================
# 3. HTML è§£æé€»è¾‘ (ä¿æŒç´§å‡‘æ’ç‰ˆ)
# ===========================
def parse_html(html_content, target_year):
    soup = BeautifulSoup(html_content, 'html.parser')
    events_map = {}
    rows = soup.find_all('tr')
    
    if len(rows) < 10:
        print(f"âŒ [{target_year}] è§£æå¤±è´¥ï¼šé¡µé¢æ— æ•ˆã€‚")
        return []

    print(f"ğŸ” [{target_year}] æ‰«æåˆ° {len(rows)} è¡Œï¼Œå¼€å§‹è§£æ...")

    current_month = 1
    current_day = 0
    
    exclude_exact = [
        'æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥', 'ä¸»æ—¥',
        'è‡ª*', 'è‡ª', 'O', 'M', 'F', 'S', 'P', 'W', 'R', 'G', 'V', 'L', 'D', 'Lit.', 'Ordo',
        'I', 'II', 'III', 'IV', 'V'
    ]
    month_names = ['ä¸€æœˆ', 'äºŒæœˆ', 'ä¸‰æœˆ', 'å››æœˆ', 'äº”æœˆ', 'å…­æœˆ', 'ä¸ƒæœˆ', 'å…«æœˆ', 'ä¹æœˆ', 'åæœˆ', 'åä¸€æœˆ', 'åäºŒæœˆ']

    for row in rows:
        row_text = row.get_text(strip=True)
        
        # æ—¥æœŸå®šä½
        day_num = None
        date_match = re.search(r'(\d{1,2})\s*[æœˆ/]\s*(\d{1,2})', row_text)
        if date_match:
            try:
                m = int(date_match.group(1)); d = int(date_match.group(2))
                if 1 <= m <= 12 and 1 <= d <= 31: current_month = m; day_num = d
            except: pass
        
        if day_num is None:
            for cell in row.find_all(['td', 'th']):
                if cell.get_text(strip=True).isdigit():
                    d = int(cell.get_text(strip=True))
                    if 1 <= d <= 31:
                        if d == current_day + 1 or d == 1 or d == current_day: day_num = d; break

        if day_num is not None:
            if day_num < current_day and current_month < 12 and day_num == 1: current_month += 1
            current_day = day_num
        else:
            if current_day == 0: continue
            if row_text in month_names or "æœˆ" in row_text and len(row_text) < 4: continue
            if "æ˜ŸæœŸ" in row_text and "æ—¥æœŸ" in row_text: continue

        # æå–å†…å®¹
        for cell in row.find_all(['td', 'th']):
            cell_text = cell.get_text(strip=True, separator=' ')
            
            if re.match(r'^[\d\s/-]+$', cell_text) or re.match(r'^\d+æœˆ\d+æ—¥$', cell_text): continue
            if cell_text in month_names or cell_text in exclude_exact: continue
            if "æ—¥æœŸ" in cell_text: continue
            if cell_text.replace('*', '').strip() in ['è‡ª', 'O', 'M']: continue
            if len(cell_text) < 2 and not re.search(r'[\u4e00-\u9fff]', cell_text): continue

            # åŸºç¡€æ¸…æ´—
            clean_text = cell_text.replace('è‡ª*', '').replace('è‡ª ', '').strip()
            clean_text = re.sub(r'^\d+\s*', '', clean_text)
            
            # æ ‡ç‚¹ç´§å‡‘åŒ–
            clean_text = clean_text.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
            for char in ['ã€', 'ï¼Œ', 'ã€‚', 'ï¼', 'ãƒ»', 'â€§', 'ï½¥']:
                clean_text = clean_text.replace(char, '.')
            
            clean_text = re.sub(r'([\u4e00-\u9fff])\s+([\u4e00-\u9fff])', r'\1\2', clean_text)
            clean_text = re.sub(r'\s*\.\s*', '.', clean_text)
            clean_text = re.sub(r'\s*\(\s*', '(', clean_text)
            clean_text = re.sub(r'\s*\)\s*', ')', clean_text)

            if len(clean_text) > 1:
                # è·å–é¢œè‰²
                emoji_prefix = get_liturgical_emoji(cell, row, clean_text)
                
                try:
                    dt = datetime(target_year, current_month, current_day)
                    if dt not in events_map: events_map[dt] = []
                    
                    final_text = f"{emoji_prefix}{clean_text}"
                    if final_text not in events_map[dt]:
                        events_map[dt].append(final_text)
                except ValueError: continue

    sorted_events = []
    for dt in sorted(events_map.keys()):
        full_summary = " | ".join(events_map[dt])
        sorted_events.append({'date': dt, 'summary': full_summary})

    print(f"âœ… [{target_year}] è§£ææˆåŠŸ: {len(sorted_events)} æ¡æ•°æ®")
    return sorted_events

# ===========================
# 4. ç”Ÿæˆæ¨¡å—
# ===========================
def generate_ics(events, output_file, calendar_name, convert_to_simplified=False):
    cal = Calendar()
    cal.add('prodid', '-//GCatholic HK//mxm.io//')
    cal.add('version', '2.0')
    cal.add('x-wr-calname', calendar_name)
    cal.add('x-wr-timezone', 'Asia/Hong_Kong')
    
    for e in events:
        event = Event()
        summary = e['summary']
        if convert_to_simplified and zhconv: summary = zhconv.convert(summary, 'zh-cn')
        
        uid = hashlib.md5(f"{e['date']}{summary}".encode()).hexdigest() + "@gcatholic"
        event.add('summary', summary)
        event.add('dtstart', e['date'].date())
        event.add('dtend', (e['date'] + timedelta(days=1)).date())
        event.add('uid', uid)
        cal.add_component(event)

    with open(output_file, 'wb') as f: f.write(cal.to_ical())

if __name__ == "__main__":
    TASKS = [
        { "year": 2026, "url": "https://gcatholic.org/calendar/2026/HK-zt" },
        { "year": 2027, "url": "https://gcatholic.org/calendar/2027/General-D-zt" },
        { "year": 2028, "url": "https://gcatholic.org/calendar/2028/General-D-zt" },
        { "year": 2029, "url": "https://gcatholic.org/calendar/2029/General-D-zt" }
    ]
    
    master_events = []
    print("ğŸš€ å¯åŠ¨ä»»åŠ¡ (2026-2029) + æ™ºèƒ½é¢œè‰² + ç´§å‡‘æ’ç‰ˆ...")
    
    for task in TASKS:
        if master_events: time.sleep(random.randint(5, 8))
        html = fetch_calendar_data(task['url'])
        if html:
            master_events.extend(parse_html(html, task['year']))
        else:
            print(f"âš ï¸ è·³è¿‡ {task['year']} å¹´")

    if master_events:
        master_events.sort(key=lambda x: x['date'])
        print(f"\nğŸ“Š æ€»è®¡: {len(master_events)} æ¡æ•°æ®ã€‚æ­£åœ¨ç”Ÿæˆ...")
        generate_ics(master_events, "catholic_calendar_2026-2029.ics", "å¤©ä¸»æ•™ç¤¼ä»ªæ—¥å† 2026-2029")
        if zhconv:
            generate_ics(master_events, "catholic_calendar_2026-2029_cn.ics", "å¤©ä¸»æ•™ç¤¼ä»ªæ—¥å† 2026-2029 (ç®€)", True)
        print("ğŸ‰ å®Œæˆï¼")
